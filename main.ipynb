{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "np.random.seed(2019)\n",
    "\n",
    "log_path = datetime.now().strftime('./logs/%Y-%m-%d-%H-%M-%S.log')\n",
    "logging.basicConfig(filename=log_path, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(dp):\n",
    "    x = []\n",
    "    for fn in sorted(os.listdir(dp), key=lambda y: int(y[:-4])):\n",
    "        with open('{dp}{fn}'.format(dp=dp, fn=fn), 'r') as f:\n",
    "            x.append(f.read())\n",
    "    return x\n",
    "\n",
    "x_tr_pos = np.array(load_data('./dataset/train/pos/'), dtype=np.str)\n",
    "x_tr_neg = np.array(load_data('./dataset/train/neg/'), dtype=np.str)\n",
    "x_tr = np.concatenate((x_tr_pos, x_tr_neg), axis=0)\n",
    "y_tr = np.concatenate((np.ones_like(x_tr_pos, dtype=np.float64), np.zeros_like(x_tr_neg, dtype=np.float64)), axis=0)\n",
    "x_ts = np.array(load_data('./dataset/test/'), dtype=np.str)\n",
    "\n",
    "del x_tr_pos\n",
    "del x_tr_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is a necessary step to prevent KFold splits consisting only one class\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_tr, y_tr = shuffle(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocessor(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace('<br /><br />', ' ')\n",
    "    s = s.replace('-', ' ')\n",
    "    s = s.replace('/', ' ')\n",
    "    for ws in string.whitespace:\n",
    "        s.replace(ws, ' ')\n",
    "    s = s.translate(s.maketrans('', '', string.punctuation))\n",
    "    s = s.translate(s.maketrans('', '', string.digits))\n",
    "    s = ''.join(filter(lambda x: x in string.printable, s))\n",
    "    return s\n",
    "\n",
    "def tokenizer(s):\n",
    "    wl = WordNetLemmatizer()\n",
    "    st = SnowballStemmer('english', ignore_stopwords=True)\n",
    "    ts = word_tokenize(s, 'english')\n",
    "    ts = list(filter(lambda x: x not in stopwords.words('english'), ts))\n",
    "    ts = list(map(lambda x: wl.lemmatize(x), ts))\n",
    "    ts = list(map(lambda x: st.stem(x), ts))\n",
    "    return ts\n",
    "\n",
    "token_pattern = r'\\w+|[%s]' % string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idf_transform(x_tr, x_ts):\n",
    "    st_time = datetime.now()\n",
    "\n",
    "    tf_idf = TfidfVectorizer(token_pattern=token_pattern,\n",
    "                             ngram_range=(1, 3))\n",
    "    x_tr = tf_idf.fit_transform(x_tr)\n",
    "    x_ts = tf_idf.transform(x_ts)\n",
    "\n",
    "    fn_time = datetime.now()\n",
    "    logger.info('Total Time Tfidf Vectorizer: {tt}'.format(tt=fn_time - st_time))\n",
    "\n",
    "    return x_tr, x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def count_transform(x_tr, x_ts):\n",
    "    st_time = datetime.now()\n",
    "\n",
    "    cnt = CountVectorizer(token_pattern=token_pattern,\n",
    "                          ngram_range=(1, 3))\n",
    "    x_tr = cnt.fit_transform(x_tr)\n",
    "    x_ts = cnt.transform(x_ts)\n",
    "\n",
    "    fn_time = datetime.now()\n",
    "    logger.info('Total Time Count Vectorizer: {tt}'.format(tt=fn_time - st_time))\n",
    "\n",
    "    return x_tr, x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def binary_transform(x_tr, x_ts):\n",
    "    st_time = datetime.now()\n",
    "\n",
    "    cnt = CountVectorizer(token_pattern=token_pattern,\n",
    "                          ngram_range=(1, 3),\n",
    "                          binary=True)\n",
    "    x_tr = cnt.fit_transform(x_tr)\n",
    "    x_ts = cnt.transform(x_ts)\n",
    "\n",
    "    fn_time = datetime.now()\n",
    "    logger.info('Total Time Binary Vectorizer: {tt}'.format(tt=fn_time - st_time))\n",
    "\n",
    "    return x_tr, x_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def k_fold_cross_validation(k, cl, x_tr, y_tr, vec):\n",
    "    st_time = datetime.now()\n",
    "\n",
    "    cv_s = []\n",
    "    kf_res = []\n",
    "    for i, (tr_idx, cv_idx) in enumerate(KFold(n_splits=k).split(x_tr)):\n",
    "        x_cnt_tr, x_cnt_ts = vec(x_tr[tr_idx], x_tr[cv_idx])\n",
    "        cl.fit(x_cnt_tr, y_tr[tr_idx])\n",
    "\n",
    "        kf_res.append((cl.predict(x_cnt_tr), cl.predict(x_cnt_ts)))\n",
    "        cv_s.append(f1_score(y_tr[cv_idx], kf_res[-1][1]))\n",
    "\n",
    "        logger.info('KFold {} CV Score: {}'.format(i, cv_s[-1]))\n",
    "    logger.info('KFold Mean CV Score: {}'.format(sum(cv_s) / k))\n",
    "\n",
    "    fn_time = datetime.now()\n",
    "    logger.info('Total Time KFold CV ({k}): {tt}'.format(k=k, tt=fn_time - st_time))\n",
    "\n",
    "    return kf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(cl, x_tr, y_tr, x_ts, fn, vec):\n",
    "    st_time = datetime.now()\n",
    "\n",
    "    x_tr, x_ts = vec(x_tr, x_ts)\n",
    "    cl.fit(x_tr, y_tr)\n",
    "    with open('./results/{fn}.csv'.format(fn=fn), 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        prd = cl.predict(x_ts)\n",
    "        for i, y_i in enumerate(prd):\n",
    "            f.write('{i},{y_i}\\n'.format(i=i, y_i=int(y_i)))\n",
    "\n",
    "    fn_time = datetime.now()\n",
    "    logger.info('Total Time Prediction: {tt}'.format(tt=fn_time - st_time))\n",
    "\n",
    "    return prd, cl.predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def run_model(cl, k, x_tr, y_tr, x_ts, vec, fn):\n",
    "    kf_res_ = k_fold_cross_validation(k, clone(cl), x_tr, y_tr, vec)\n",
    "    prd_ts, prd_tr = predict_test(clone(cl), x_tr, y_tr, x_ts, fn, vec)\n",
    "    return kf_res_, prd_ts, prd_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression Binary:\n",
      "Total Time Binary Vectorizer: 0:01:00.733377\n",
      "KFold 0 CV Score: 0.8950715421303658\n",
      "Total Time Binary Vectorizer: 0:01:01.976838\n",
      "KFold 1 CV Score: 0.8957403651115617\n",
      "Total Time Binary Vectorizer: 0:00:57.816473\n",
      "KFold 2 CV Score: 0.9057560975609756\n",
      "Total Time Binary Vectorizer: 0:00:48.505445\n",
      "KFold 3 CV Score: 0.9042298483639266\n",
      "Total Time Binary Vectorizer: 0:00:50.064177\n",
      "KFold 4 CV Score: 0.8960601861017621\n",
      "KFold Mean CV Score: 0.8993716078537183\n",
      "Total Time KFold CV (5): 0:12:40.833318\n",
      "Total Time Binary Vectorizer: 0:01:18.556920\n",
      "Total Time: 0:02:55.437742\n",
      "\n",
      "LogisticRegression Count:\n",
      "Total Time Count Vectorizer: 0:00:50.297688\n",
      "KFold 0 CV Score: 0.8994624726259207\n",
      "Total Time Count Vectorizer: 0:00:50.157655\n",
      "KFold 1 CV Score: 0.8986390412350193\n",
      "Total Time Count Vectorizer: 0:00:49.716529\n",
      "KFold 2 CV Score: 0.9006648416112631\n",
      "Total Time Count Vectorizer: 0:00:48.494790\n",
      "KFold 3 CV Score: 0.9008828250401284\n",
      "Total Time Count Vectorizer: 0:00:50.024349\n",
      "KFold 4 CV Score: 0.8976845438353453\n",
      "KFold Mean CV Score: 0.8994667448695355\n",
      "Total Time KFold CV (5): 0:10:51.806966\n",
      "Total Time Count Vectorizer: 0:01:25.677706\n",
      "Total Time: 0:03:09.018448\n",
      "\n",
      "LogisticRegression Tfidf:\n",
      "Total Time Tfidf Vectorizer: 0:01:02.211909\n",
      "KFold 0 CV Score: 0.8747016706443915\n",
      "Total Time Tfidf Vectorizer: 0:00:55.972545\n",
      "KFold 1 CV Score: 0.8804040404040404\n",
      "Total Time Tfidf Vectorizer: 0:00:57.487590\n",
      "KFold 2 CV Score: 0.8772682926829268\n",
      "Total Time Tfidf Vectorizer: 0:00:54.362070\n",
      "KFold 3 CV Score: 0.8813627254509019\n",
      "Total Time Tfidf Vectorizer: 0:00:58.985530\n",
      "KFold 4 CV Score: 0.8854599406528191\n",
      "KFold Mean CV Score: 0.879839333967016\n",
      "Total Time KFold CV (5): 0:09:07.569602\n",
      "Total Time Tfidf Vectorizer: 0:02:08.688082\n",
      "Total Time: 0:03:47.429684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cl_lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "logger.info('LogisticRegression Binary:')\n",
    "kf_res_lr_bn, prd_ts_lr_bn, prd_tr_lr_bn = run_model(cl_lr, 5, x_tr, y_tr, x_ts,\n",
    "                                                     binary_transform, 'logistic_regression_binary')\n",
    "logger.info('\\nLogisticRegression Count:')\n",
    "kf_res_lr_cn, prd_ts_lr_cn, prd_tr_lr_cn = run_model(cl_lr, 5, x_tr, y_tr, x_ts,\n",
    "                                                     count_transform, 'logistic_regression_count')\n",
    "logger.info('\\nLogisticRegression Tfidf:')\n",
    "kf_res_lr_ti, prd_ts_lr_ti, prd_tr_lr_ti = run_model(cl_lr, 5, x_tr, y_tr, x_ts,\n",
    "                                                     tf_idf_transform, 'logistic_regression_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearSVC Binary:\n",
      "Total Time Binary Vectorizer: 0:01:07.914878\n",
      "/usr/local/anaconda3/envs/comp551/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "KFold 0 CV Score: 0.893879173290938\n",
      "Total Time Binary Vectorizer: 0:01:06.806678\n",
      "KFold 1 CV Score: 0.89353921170256\n",
      "Total Time Binary Vectorizer: 0:00:59.259294\n",
      "KFold 2 CV Score: 0.90234375\n",
      "Total Time Binary Vectorizer: 0:00:55.502179\n",
      "KFold 3 CV Score: 0.9022827392871445\n",
      "Total Time Binary Vectorizer: 0:01:15.495726\n",
      "KFold 4 CV Score: 0.8973851030110934\n",
      "KFold Mean CV Score: 0.8978859954583471\n",
      "Total Time KFold CV (5): 0:14:12.685909\n",
      "Total Time Binary Vectorizer: 0:01:38.467866\n",
      "Total Time: 0:03:38.600600\n",
      "\n",
      "LinearSVC Count:\n",
      "Total Time Count Vectorizer: 0:00:59.177755\n",
      "KFold 0 CV Score: 0.8993235177079187\n",
      "Total Time Count Vectorizer: 0:01:06.051668\n",
      "KFold 1 CV Score: 0.8942561396387253\n",
      "Total Time Count Vectorizer: 0:00:56.426120\n",
      "KFold 2 CV Score: 0.8947677836566725\n",
      "Total Time Count Vectorizer: 0:00:49.773294\n",
      "KFold 3 CV Score: 0.8965931863727454\n",
      "Total Time Count Vectorizer: 0:00:50.874055\n",
      "KFold 4 CV Score: 0.9009724151617384\n",
      "KFold Mean CV Score: 0.8971826085075602\n",
      "Total Time KFold CV (5): 0:11:19.208893\n",
      "Total Time Count Vectorizer: 0:01:20.688038\n",
      "Total Time: 0:02:42.145227\n",
      "\n",
      "LinearSVC Tfidf:\n",
      "Total Time Tfidf Vectorizer: 0:01:08.915610\n",
      "KFold 0 CV Score: 0.9074000791452316\n",
      "Total Time Tfidf Vectorizer: 0:01:11.318505\n",
      "KFold 1 CV Score: 0.9084691209012271\n",
      "Total Time Tfidf Vectorizer: 0:01:05.192632\n",
      "KFold 2 CV Score: 0.9060859420571651\n",
      "Total Time Tfidf Vectorizer: 0:01:06.200475\n",
      "KFold 3 CV Score: 0.9082568807339448\n",
      "Total Time Tfidf Vectorizer: 0:01:11.071912\n",
      "KFold 4 CV Score: 0.9089469517022962\n",
      "KFold Mean CV Score: 0.9078317949079728\n",
      "Total Time KFold CV (5): 0:06:42.241050\n",
      "Total Time Tfidf Vectorizer: 0:01:58.419054\n",
      "Total Time: 0:02:06.484436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "cl_ls = LinearSVC()\n",
    "logger.info('LinearSVC Binary:')\n",
    "kf_res_ls_bn, prd_ts_ls_bn, prd_tr_ls_bn = run_model(cl_ls, 5, x_tr, y_tr, x_ts,\n",
    "                                                     binary_transform, 'linear_svc_binary')\n",
    "logger.info('\\nLinearSVC Count:')\n",
    "kf_res_ls_cn, prd_ts_ls_cn, prd_tr_ls_cn = run_model(cl_ls, 5, x_tr, y_tr, x_ts,\n",
    "                                                     count_transform, 'linear_svc_count')\n",
    "logger.info('\\nLinearSVC Tfidf:')\n",
    "kf_res_ls_ti, prd_ts_ls_ti, prd_tr_ls_ti = run_model(cl_ls, 5, x_tr, y_tr, x_ts,\n",
    "                                                     tf_idf_transform, 'linear_svc_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NBSVM Binary:\n",
      "Total Time Binary Vectorizer: 0:00:52.467374\n",
      "KFold 0 CV Score: 0.9195219123505977\n",
      "Total Time Binary Vectorizer: 0:01:03.812329\n",
      "KFold 1 CV Score: 0.9164985881403792\n",
      "Total Time Binary Vectorizer: 0:01:41.508223\n",
      "KFold 2 CV Score: 0.9159647404505387\n",
      "Total Time Binary Vectorizer: 0:00:54.580028\n",
      "KFold 3 CV Score: 0.9248554913294798\n",
      "Total Time Binary Vectorizer: 0:00:57.474764\n",
      "KFold 4 CV Score: 0.921825396825397\n",
      "KFold Mean CV Score: 0.9197332258192784\n",
      "Total Time KFold CV (5): 0:16:47.133925\n",
      "Total Time Binary Vectorizer: 0:01:29.264890\n",
      "Total Time: 0:03:25.421935\n",
      "\n",
      "NBSVM Count:\n",
      "Total Time Count Vectorizer: 0:00:51.945422\n",
      "KFold 0 CV Score: 0.9227101132525333\n",
      "Total Time Count Vectorizer: 0:01:03.228642\n",
      "KFold 1 CV Score: 0.91727199354318\n",
      "Total Time Count Vectorizer: 0:01:00.438501\n",
      "KFold 2 CV Score: 0.9143976493633693\n",
      "Total Time Count Vectorizer: 0:01:06.740401\n",
      "KFold 3 CV Score: 0.9226464121527084\n",
      "Total Time Count Vectorizer: 0:00:52.781187\n",
      "KFold 4 CV Score: 0.9235946159936659\n",
      "KFold Mean CV Score: 0.9201241568610914\n",
      "Total Time KFold CV (5): 0:15:43.445743\n",
      "Total Time Count Vectorizer: 0:02:02.540981\n",
      "Total Time: 0:05:20.181915\n",
      "\n",
      "NBSVM Tfidf:\n",
      "Total Time Tfidf Vectorizer: 0:01:11.083286\n",
      "KFold 0 CV Score: 0.9019375247133254\n",
      "Total Time Tfidf Vectorizer: 0:01:03.424944\n",
      "KFold 1 CV Score: 0.8976157082748949\n",
      "Total Time Tfidf Vectorizer: 0:01:04.563394\n",
      "KFold 2 CV Score: 0.9035769828926904\n",
      "Total Time Tfidf Vectorizer: 0:01:13.862953\n",
      "KFold 3 CV Score: 0.9090185148317738\n",
      "Total Time Tfidf Vectorizer: 0:01:03.526077\n",
      "KFold 4 CV Score: 0.9065934065934066\n",
      "KFold Mean CV Score: 0.9037484274612183\n",
      "Total Time KFold CV (5): 0:06:34.723022\n",
      "Total Time Tfidf Vectorizer: 0:01:43.201610\n",
      "Total Time: 0:01:55.476005\n"
     ]
    }
   ],
   "source": [
    "from nbsvm import NBSVM\n",
    "\n",
    "cl_ns = NBSVM()\n",
    "logger.info('NBSVM Binary:')\n",
    "kf_res_ns_bn, prd_ts_ns_bn, prd_tr_ns_bn = run_model(cl_ns, 5, x_tr, y_tr, x_ts,\n",
    "                                                     binary_transform, 'nb_svm_binary')\n",
    "logger.info('\\nNBSVM Count:')\n",
    "kf_res_ns_cn, prd_ts_ns_cn, prd_tr_ns_cn = run_model(cl_ns, 5, x_tr, y_tr, x_ts,\n",
    "                                                     count_transform, 'nb_svm_count')\n",
    "logger.info('\\nNBSVM Tfidf:')\n",
    "kf_res_ns_ti, prd_ts_ns_ti, prd_tr_ns_ti = run_model(cl_ns, 5, x_tr, y_tr, x_ts,\n",
    "                                                     tf_idf_transform, 'nb_svm_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BernoulliNB Binary:\n",
      "Total Time Binary Vectorizer: 0:00:50.554297\n",
      "KFold 0 CV Score: 0.8691430983537357\n",
      "Total Time Binary Vectorizer: 0:00:51.120874\n",
      "KFold 1 CV Score: 0.8892116182572614\n",
      "Total Time Binary Vectorizer: 0:00:52.904800\n",
      "KFold 2 CV Score: 0.8671563483735572\n",
      "Total Time Binary Vectorizer: 0:00:50.753494\n",
      "KFold 3 CV Score: 0.8765224695506089\n",
      "Total Time Binary Vectorizer: 0:00:51.343319\n",
      "KFold 4 CV Score: 0.8746318889356332\n",
      "KFold Mean CV Score: 0.8753330846941593\n",
      "Total Time KFold CV (5): 0:04:38.677145\n",
      "Total Time Binary Vectorizer: 0:01:21.364457\n",
      "Total Time: 0:01:23.710896\n",
      "\n",
      "BernoulliNB Count:\n",
      "Total Time Count Vectorizer: 0:00:52.309309\n",
      "KFold 0 CV Score: 0.8691430983537357\n",
      "Total Time Count Vectorizer: 0:00:54.923399\n",
      "KFold 1 CV Score: 0.8892116182572614\n",
      "Total Time Count Vectorizer: 0:00:51.249935\n",
      "KFold 2 CV Score: 0.8671563483735572\n",
      "Total Time Count Vectorizer: 0:00:53.471255\n",
      "KFold 3 CV Score: 0.8765224695506089\n",
      "Total Time Count Vectorizer: 0:00:50.836715\n",
      "KFold 4 CV Score: 0.8746318889356332\n",
      "KFold Mean CV Score: 0.8753330846941593\n",
      "Total Time KFold CV (5): 0:04:44.773350\n",
      "Total Time Count Vectorizer: 0:01:23.015791\n",
      "Total Time: 0:01:25.144814\n",
      "\n",
      "BernoulliNB Tfidf:\n",
      "Total Time Tfidf Vectorizer: 0:00:57.268473\n",
      "KFold 0 CV Score: 0.8691430983537357\n",
      "Total Time Tfidf Vectorizer: 0:00:58.953284\n",
      "KFold 1 CV Score: 0.8892116182572614\n",
      "Total Time Tfidf Vectorizer: 0:00:56.270434\n",
      "KFold 2 CV Score: 0.8671563483735572\n",
      "Total Time Tfidf Vectorizer: 0:00:55.926185\n",
      "KFold 3 CV Score: 0.8765224695506089\n",
      "Total Time Tfidf Vectorizer: 0:01:23.648258\n",
      "KFold 4 CV Score: 0.8746318889356332\n",
      "KFold Mean CV Score: 0.8753330846941593\n",
      "Total Time KFold CV (5): 0:05:28.324128\n",
      "Total Time Tfidf Vectorizer: 0:01:40.089159\n",
      "Total Time: 0:01:42.071337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "cl_bn = BernoulliNB()\n",
    "logger.info('BernoulliNB Binary:')\n",
    "kf_res_bn_bn, prd_ts_bn_bn, prd_tr_bn_bn = run_model(cl_bn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     binary_transform, 'bernoulli_naive_bayes_binary')\n",
    "logger.info('\\nBernoulliNB Count:')\n",
    "kf_res_bn_cn, prd_ts_bn_cn, prd_tr_bn_cn = run_model(cl_bn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     count_transform, 'bernoulli_naive_bayes_count')\n",
    "logger.info('\\nBernoulliNB Tfidf:')\n",
    "kf_res_bn_ti, prd_ts_bn_ti, prd_tr_bn_ti = run_model(cl_bn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     tf_idf_transform, 'bernoulli_naive_bayes_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialNB Binary:\n",
      "Total Time Binary Vectorizer: 0:01:07.101059\n",
      "KFold 0 CV Score: 0.8868889343424013\n",
      "Total Time Binary Vectorizer: 0:01:00.631669\n",
      "KFold 1 CV Score: 0.8912952936276552\n",
      "Total Time Binary Vectorizer: 0:01:02.588041\n",
      "KFold 2 CV Score: 0.8844118844118843\n",
      "Total Time Binary Vectorizer: 0:00:52.684926\n",
      "KFold 3 CV Score: 0.8873239436619719\n",
      "Total Time Binary Vectorizer: 0:01:10.023258\n",
      "KFold 4 CV Score: 0.8906633906633907\n",
      "KFold Mean CV Score: 0.8881166893414607\n",
      "Total Time KFold CV (5): 0:05:34.226930\n",
      "Total Time Binary Vectorizer: 0:01:24.975771\n",
      "Total Time: 0:01:26.701356\n",
      "\n",
      "MultinomialNB Count:\n",
      "Total Time Count Vectorizer: 0:00:53.129203\n",
      "KFold 0 CV Score: 0.8822567457072772\n",
      "Total Time Count Vectorizer: 0:00:50.348165\n",
      "KFold 1 CV Score: 0.8866108786610877\n",
      "Total Time Count Vectorizer: 0:00:50.417470\n",
      "KFold 2 CV Score: 0.8769574944071589\n",
      "Total Time Count Vectorizer: 0:00:48.970740\n",
      "KFold 3 CV Score: 0.8786749482401657\n",
      "Total Time Count Vectorizer: 0:00:50.059661\n",
      "KFold 4 CV Score: 0.8844654217114714\n",
      "KFold Mean CV Score: 0.881793097745432\n",
      "Total Time KFold CV (5): 0:04:28.809885\n",
      "Total Time Count Vectorizer: 0:01:22.429813\n",
      "Total Time: 0:01:24.188387\n",
      "\n",
      "MultinomialNB Tfidf:\n",
      "Total Time Tfidf Vectorizer: 0:00:56.717014\n",
      "KFold 0 CV Score: 0.875655273642273\n",
      "Total Time Tfidf Vectorizer: 0:00:55.533294\n",
      "KFold 1 CV Score: 0.8851493479175431\n",
      "Total Time Tfidf Vectorizer: 0:00:56.111744\n",
      "KFold 2 CV Score: 0.8609411268200043\n",
      "Total Time Tfidf Vectorizer: 0:01:01.740490\n",
      "KFold 3 CV Score: 0.8591549295774648\n",
      "Total Time Tfidf Vectorizer: 0:00:58.762484\n",
      "KFold 4 CV Score: 0.8731327582579425\n",
      "KFold Mean CV Score: 0.8708066872430456\n",
      "Total Time KFold CV (5): 0:05:04.296736\n",
      "Total Time Tfidf Vectorizer: 0:01:33.518672\n",
      "Total Time: 0:01:35.019263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "cl_mn = MultinomialNB()\n",
    "logger.info('MultinomialNB Binary:')\n",
    "kf_res_mn_bn, prd_ts_mn_bn, prd_tr_mn_bn = run_model(cl_mn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     binary_transform, 'multinomial_naive_bayes_binary')\n",
    "logger.info('\\nMultinomialNB Count:')\n",
    "kf_res_mn_cn, prd_ts_mn_cn, prd_tr_mn_cn = run_model(cl_mn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     count_transform, 'multinomial_naive_bayes_count')\n",
    "logger.info('\\nMultinomialNB Tfidf:')\n",
    "kf_res_mn_ti, prd_ts_mn_ti, prd_tr_mn_ti = run_model(cl_mn, 5, x_tr, y_tr, x_ts,\n",
    "                                                     tf_idf_transform, 'multinomial_naive_bayes_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold 0 CV Score: 0.91256721768572\n",
      "KFold 1 CV Score: 0.9136603161734901\n",
      "KFold 2 CV Score: 0.9109803921568628\n",
      "KFold 3 CV Score: 0.91705161679052\n",
      "KFold 4 CV Score: 0.914228855721393\n",
      "KFold Mean CV Score: 0.9136976797055972\n"
     ]
    }
   ],
   "source": [
    "# NOTE: The logic of CV in this stacking has some problems.\n",
    "\n",
    "cv_s = []\n",
    "cls_cv = [\n",
    "    kf_res_lr_bn, kf_res_lr_cn, kf_res_lr_ti,\n",
    "    kf_res_ls_bn, kf_res_ls_cn, kf_res_ls_ti,\n",
    "    kf_res_ns_bn, kf_res_ns_cn, kf_res_ns_ti,\n",
    "    kf_res_bn_bn, kf_res_bn_cn, kf_res_bn_ti,\n",
    "    kf_res_mn_bn, kf_res_mn_cn, kf_res_mn_ti,\n",
    "    KFold(n_splits=5).split(x_tr)\n",
    "]\n",
    "cl_stk_lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "for i, kf_i in enumerate(zip(*cls_cv)):\n",
    "    cl_stk_lr.fit(np.concatenate(list(map(lambda x: x[0].reshape((-1, 1)), kf_i[:-1])), axis=1), y_tr[kf_i[-1][0]])\n",
    "    cv_s.append(f1_score(y_tr[kf_i[-1][1]], cl_stk_lr.predict(np.concatenate(list(map(lambda x: x[1].reshape((-1, 1)), kf_i[:-1])), axis=1))))\n",
    "    logger.info('KFold {} CV Score: {}'.format(i, cv_s[-1]))\n",
    "logger.info('KFold Mean CV Score: {}'.format(sum(cv_s) / len(cv_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_ts = [\n",
    "    prd_ts_lr_bn, prd_ts_lr_cn, prd_ts_lr_ti,\n",
    "    prd_ts_ls_bn, prd_ts_ls_cn, prd_ts_ls_ti,\n",
    "    prd_ts_ns_bn, prd_ts_ns_cn, prd_ts_ns_ti,\n",
    "    prd_ts_bn_bn, prd_ts_bn_cn, prd_ts_bn_ti,\n",
    "    prd_ts_mn_bn, prd_ts_mn_cn, prd_ts_mn_ti,\n",
    "]\n",
    "cls_tr = [\n",
    "    prd_tr_lr_bn, prd_tr_lr_cn, prd_tr_lr_ti,\n",
    "    prd_tr_ls_bn, prd_tr_ls_cn, prd_tr_ls_ti,\n",
    "    prd_tr_ns_bn, prd_tr_ns_cn, prd_tr_ns_ti,\n",
    "    prd_tr_bn_bn, prd_tr_bn_cn, prd_tr_bn_ti,\n",
    "    prd_tr_mn_bn, prd_tr_mn_cn, prd_tr_mn_ti,\n",
    "]\n",
    "cl_stk_lr.fit(np.concatenate(list(map(lambda x: x.reshape((-1, 1)), cls_tr)), axis=1), y_tr)\n",
    "with open('./results/stacked_everything.csv', 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    prd = cl_stk_lr.predict(np.concatenate(list(map(lambda x: x.reshape((-1, 1)), cls_tr)), axis=1))\n",
    "    for i, y_i in enumerate(prd):\n",
    "        f.write('{i},{y_i}\\n'.format(i=i, y_i=int(y_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only run this to generate the info gain csv\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "vecs = [(TfidfVectorizer(token_pattern=token_pattern, ngram_range=(1, 3)), 'tf_idf'),\n",
    "        (CountVectorizer(token_pattern=token_pattern, ngram_range=(1, 3)), 'count'),\n",
    "        (CountVectorizer(token_pattern=token_pattern, ngram_range=(1, 3), binary=True), 'binary')]\n",
    "for vec, vec_nm in vecs:\n",
    "    mu_ig = mutual_info_classif(vec.fit_transform(x_tr), y_tr)\n",
    "    with open('./files/information_gain_{vec_nm}.csv'.format(vec_nm=vec_nm), 'w') as f:\n",
    "        for mi_i, fn_i in sorted(zip(mu_ig, fn), key=lambda x: -x[0]):\n",
    "            f.write('{mi_i},{fn_i}\\n'.format(mi_i=mi_i, fn_i=fn_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
